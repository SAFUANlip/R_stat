# Try Box-Cox
if (sum(x <= 0)){
x_shifted <- x + abs(min(x)) + 1
print("Shifted for Box-Cox transform")
}
else{
x_shifted <- x
}
bc_model <- powerTransform(x_shifted ~ 1, family = "bcPower")
if (!is.null(bc_model)) {
lambda_bc <- bc_model$lambda
x_bc <- bcPower(x_shifted, lambda_bc)
p_bc <- tryCatch(shapiro.test(x_bc)$p.value, error = function(e) NA)
if (!is.na(p_bc) && p_bc > best_p) {
best_p <- p_bc
best_transform <- "Box-Cox"
best_data <- x_bc
best_lambda <- lambda_bc
}
}
# Try Yeo-Johnson
yj_model <- tryCatch(powerTransform(x ~ 1, family = "yjPower"), error = function(e) NULL)
if (!is.null(yj_model)) {
lambda_yj <- yj_model$lambda
x_yj <- yjPower(x, lambda_yj)
p_yj <- tryCatch(shapiro.test(x_yj)$p.value, error = function(e) NA)
if (!is.na(p_yj) && p_yj > best_p) {
best_p <- p_yj
best_transform <- "YeoJohnson"
best_data <- x_yj
best_lambda <- lambda_yj
}
}
# Save best transformed variable
transformed_data[[feature]] <- best_data
summary_table <- rbind(summary_table, data.frame(
Variable = feature,
Original_p = round(p_original, 4),
Best_Transform = best_transform,
Best_p = round(best_p, 4),
Lambda = round(best_lambda, 4),
stringsAsFactors = FALSE
))
}
return(list(
transformed_data = transformed_data,
summary = summary_table
))
}
if (sum(pollution$PM2.5 < 0)){
print("Have zero negative values")
}
if (sum(b$x < 0)){
print("Have zero negative values")
}
transformed_res_b <- find_best_transforms(b)
transformed_res_b$summary
transformed_res_pollution <- find_best_transforms(pollution)
transformed_res_pollution$summary
pollution_transformed <- transformed_res_pollution$transformed_data
qqnorm(pollution_transformed$PM2.5)
qqnorm(pollution_transformed$PM10)
qqnorm(pollution$PM2.5)
qqnorm(pollution$PM10)
mvn(pollution)
mvn(pollution_transformed)
qqnorm(transformed_res_b$transformed_data$x)
qqnorm(pollution$transformed_data$y)
qqnorm(transformed_res_b$transformed_data$y)
## Example 1: Simulated multivariate normal sample --------------------------------------------
# We generate a sample of n=150 observation from bivariate Gaussian
mu <- c(1, 2)
### Multivariate Box-Cox transformation (J-W, Ch. 4.8)
# Similar to univariate transformation, but jointly on all the variables
rm(x)
detach(b)
## Example 3: Board stiffness dataset ---------------------------------------------------------
stiff <- read.table('stiff.dat')
head(stiff)
dim(stiff)
lambda.mult <- powerTransform(stiff)
lambda.mult
BC.x <- bcPower(stiff[, 1], lambda.mult$lambda[1])
BC.y <- bcPower(stiff[, 2], lambda.mult$lambda[2])
BC.z <- bcPower(stiff[, 3], lambda.mult$lambda[3])
BC.w <- bcPower(stiff[, 4], lambda.mult$lambda[4])
# Plot of the original variables
attach(stiff)
plot.hist.qq <- function(stiff) {
par(mfrow=c(2,4))
xx<-seq(1320, 3000, length=100)
hist(V1, prob=T, breaks=8, col='grey85')
lines(xx, dnorm(xx,mean(V1), sd(V1)), col='blue', lty=2)
yy<-seq(1150, 2800, length=100)
hist(V2, prob=T,breaks=8,col='grey85')
lines(yy, dnorm(yy,mean(V2), sd(V2)), col='blue', lty=2)
zz<-seq(1000, 2420, length=100)
hist(V3, prob=T, breaks=8, col='grey85')
lines(zz, dnorm(zz,mean(V3), sd(V3)), col='blue', lty=2)
ww<-seq(1100, 2600, length=100)
hist(V4, prob=T, breaks=8, col='grey85')
lines(ww, dnorm(ww, mean(V4), sd(V4)), col='blue', lty=2)
qqnorm(V1, main='QQplot of V1')
qqline(V1)
qqnorm(V2, main='QQplot of V2')
qqline(V2)
qqnorm(V3, main='QQplot of V3')
qqline(V3)
qqnorm(V4, main='QQplot of V4')
qqline(V4)
}
plot.hist.qq(stiff)
detach(stiff)
# Plot of the transformed variables
plot.hist.qq.bc <- function() {
par(mfrow=c(2,4))
xx<-seq(10, 12, length=100)
hist(BC.x, prob=T, breaks=8, col='grey85')
lines(xx, dnorm(xx, mean(BC.x), sd(BC.x)), col='blue', lty=2)
yy<-seq(3, 3.2, length=100)
hist(BC.y, prob=T, breaks=8, col='grey85')
lines(yy, dnorm(yy, mean(BC.y), sd(BC.y)), col='blue', lty=2)
zz<-seq(12, 15, length=100)
hist(BC.z, prob=T, breaks=8, col='grey85')
lines(zz, dnorm(zz, mean(BC.z), sd(BC.z)), col='blue', lty=2)
ww<-seq(250, 500, length=100)
hist(BC.w, prob=T, breaks=8, col='grey85')
lines(ww, dnorm(ww, mean(BC.w), sd(BC.w)), col='blue', lty=2)
qqnorm(BC.x, main='QQplot of BC.x')
qqline(BC.x)
qqnorm(BC.y, main='QQplot of BC.y')
qqline(BC.y)
qqnorm(BC.z, main='QQplot of BC.z')
qqline(BC.z)
qqnorm(BC.w, main='QQplot of BC.w')
qqline(BC.w)
par(mfrow=c(1,1))
}
plot.hist.qq.bc()
# One transformed variable at a time
shapiro.test(BC.x)
shapiro.test(BC.y)
shapiro.test(BC.z)
shapiro.test(BC.w)
# All together
mvn(cbind(BC.x, BC.y, BC.z, BC.w))$multivariateNormality # not belov 0.05, but close
## Example with simulated data from a bivariate Gaussian --------------------------------------
mu <- c(1, 0)
sig <- matrix(c(1, 1, 1, 2), nrow = 2)
set.seed(123)
x <- rmvnorm(n = 30, mean = mu, sigma = sig)
x <- data.frame(X.1 = x[, 1], X.2 = x[, 2])
plot(x, asp = 1, pch = 19)
n <- dim(x)[1]
p <- dim(x)[2]
x.mean   <- sapply(x, mean)
x.cov    <- cov(x)
x.invcov <- solve(x.cov)
# Test on the mean of level alpha=1%
# H0: mu == mu0 vs H1: mu != mu0
# with mu0 = c(1, 0)
mvn(x)$multivariateNormality
alpha <- .01
mu0 <- c(1, 0)
### Inference relying on normality -------------------------------------------------------------
# T2 Statistics
x.T2       <- n * (x.mean - mu0) %*% x.invcov %*% (x.mean - mu0)
# Radius of the ellipsoid
cfr.fisher <- ((n - 1) * p / (n - p)) * qf(1 - alpha, p, n - p)
# Test:
x.T2 < cfr.fisher   # no statistical evidence to reject H0 at level alpha
# Compute the p-value
P <- 1 - pf(x.T2 * (n - p) / ((n - 1) * p), p, n - p)
P
xx <- seq(0, 40, by = 0.05)
plot(
xx,
df(xx * (n - p) / ((n - 1) * p), p, n - p),
type = "l",
lwd = 2,
main = 'Density F(p,n-p)',
xlab = 'x*(n-p)/((n-1)*p)',
ylab = 'Density'
)
abline(
h = 0,
v = x.T2 * (n - p) / ((n - 1) * p),
col = c('grey', 'red'),
lwd = 2,
lty = c(2, 1)
)
# Region of rejection (centered in mu0)
plot(x, asp = 1)
ellipse(
mu0,
shape = x.cov / n,
sqrt(cfr.fisher),
col = 'blue',
lty = 2,
center.pch = 16
)
# We add a red point in correspondence of the sample mean
points(x.mean[1], x.mean[2], pch = 16, col ='red', cex = 1.5)
ellipse(x.mean, x.cov/n, sqrt(cfr.fisher), col = 'red', lty = 2, lwd=2, center.cex=1)
# Region of rejection (centered in mu0)
plot(x, asp = 1)
ellipse(
mu0,
shape = x.cov / n,
sqrt(cfr.fisher),
col = 'blue',
lty = 2,
center.pch = 16
)
# We add a red point in correspondence of the sample mean
points(x.mean[1], x.mean[2], pch = 16, col ='red', cex = 1.5)
ellipse(x.mean, x.cov/n, sqrt(cfr.fisher), col = 'red', lty = 2, lwd=2, center.cex=1)
# Note: we don't need to verify the Gaussian assumption!
# Warning: we are going to use an asymptotic test, but we only have n = 30 data!
# As a rule of thumb, you should consider that you don't have enough data for asymptotic test
# when n is below 30 * p^2  (p - number of variables)
mu0   <- c(1, 0)
x.T2A   <- n * (x.mean - mu0) %*%  x.invcov  %*% (x.mean - mu0)
cfr.chisq <- qchisq(1 - alpha, p)
x.T2A < cfr.chisq # no statistical evidence to reject H0 at level alpha
# Compute the p-value
PA <- 1 - pchisq(x.T2A, p)
PA
plot.exact.asympt <- function() {
par(mfrow=c(1,2))
plot(x, asp = 1,main='Comparison rejection regions')
ellipse(mu0, shape=x.cov/n, sqrt(cfr.fisher), col = 'blue', lty = 1,
center.pch = 4, center.cex=1.5, lwd=2)
ellipse(mu0, x.cov/n, sqrt(cfr.chisq), col = 'lightblue', lty = 1,
center.pch = 4, center.cex=1.5, lwd=2)
points(mu0[1], mu0[2], pch = 4, cex = 1.5, lwd = 2, col ='lightblue')
legend('topleft', c('Exact', 'Asymptotic'), col=c('blue', 'lightblue'),
lty=c(1), lwd=2)
plot(x, asp = 1,main='Comparison of confidence regions')
ellipse(x.mean, x.cov/n, sqrt(cfr.fisher), col = 'red', lty = 1, center.pch = 4,
center.cex=1.5, lwd=2)
ellipse(x.mean, x.cov/n, sqrt(cfr.chisq), col = 'orange', lty = 1, center.pch = 4,
center.cex=1.5, lwd=2)
points(x.mean[1], x.mean[2], pch = 4, cex = 1.5, lwd = 2, col ='orange')
legend('topleft', c('Exact', 'Asymptotic'), col=c('red','orange'),
lty=c(1), lwd=2)
par(mfrow = c(1, 1))
}
plot.exact.asympt()
#  We change the null Hypothesis
mu0 <- c(1.5, -0.5)
mu
# Ellipsoidal region
x.T2 <- n * t(x.mean - mu0) %*% x.invcov %*% (x.mean - mu0)
x.T2 < cfr.fisher
# Compute the p-value
P <- 1 - pf(x.T2 * (n - p) / ((n - 1) * p), p, n - p)
P
plot(x, asp = 1)
ellipse(mu0, shape=x.cov/n, sqrt(cfr.fisher), col = 'blue', lty = 2, center.pch = 16)
points(x.mean[1], x.mean[2], pch = 16, col = 'red', cex=1.5)
T2 <- cbind(inf = x.mean - sqrt(cfr.fisher*diag(x.cov)/n),
center = x.mean,
sup = x.mean + sqrt(cfr.fisher*diag(x.cov)/n))
T2
par(mfrow=c(1,1))
# Plot of the acceptance region and the sample mean
plot(x, asp = 1,main='Confidence and rejection regions')
ellipse(mu0, shape=x.cov/n, sqrt(cfr.fisher), col = 'blue', lty = 2, center.pch = 16)
points(x.mean[1], x.mean[2], pch = 16, col = 'red', cex=1.5)
# Plot of the confidence region and the region defined by the cartesian product
# of the sim. confidence intervals in direction of x1 and x2
ellipse(x.mean, shape=x.cov/n, sqrt(cfr.fisher), col = 'red', lty = 2, center.pch = 16)
rect(T2[1,1], T2[2,1], T2[1,3], T2[2,3], border='red', lwd=2)
# Let's try with Bonferroni intervals
k <- p # number of intervals I want to compute (set in advance)
cfr.t <- qt(1-alpha/(2*k), n-1)
Bf <- cbind(inf = x.mean - cfr.t*sqrt(diag(x.cov)/n),
center = x.mean,
sup = x.mean + cfr.t*sqrt(diag(x.cov)/n))
Bf
# we add the Bonferroni intervals to the plot
rect(Bf[1,1], Bf[2,1], Bf[1,3], Bf[2,3], border='orange', lwd=2)
legend('topleft', c('Rej. Reg.', 'Conf. Reg','T2-sim', 'Bonferroni'),
col=c('blue','red','red','orange'), lty=c(2,2,1,1), lwd=2)
## Example with board stiffness dataset -------------------------------------------------------
stiff <- read.table('stiff.dat')
head(stiff)
dim(stiff)
n <- dim(stiff)[1]
p <- dim(stiff)[2]
plot(stiff, pch = 19)
# Normality test
mvn(stiff)$multivariateNormality
mvn(stiff_wo_outliers)$multivariateNormality
n <- dim(stiff_wo_outliers)[1]
library(MVN) # Can need separate installation of "gsl" software library
library(car)
library(mvtnorm)
## Example 1: Simulated multivariate normal sample --------------------------------------------
# We generate a sample of n=150 observation from bivariate Gaussian
mu <- c(1, 2)
mu
sig <- matrix(c(1, 1, 1, 2), 2)
sig
n <- 150
set.seed(20230320)
X <- rmvnorm(n, mu, sig)
# Univariate Q-Q plots
par(mfrow = c(1, 2))
qqnorm(X[, 1],
main = 'QQplot of X.1',
xlab = 'theoretical quantiles',
ylab = 'sample quantiles')
qqline(X[, 1])
qqnorm(X[, 2],
main = 'QQplot of X.2',
xlab = 'theoretical quantiles',
ylab = 'sample quantiles')
qqline(X[, 2])
par(mfrow = c(1, 1))
# Tests that our sample simulated from gaussian distribution
# MVN package
# Different multivariate normality tests are implemented but the default one is the Henze-Zirkler's
result <- mvn(data = X) # By default the Henze-Zirkler's test is used (preferred)
result$multivariateNormality
# Royston’s test (multivariate extension of the Shapiro-Wilk test)
result <- mvn(data = X, mvnTest = "royston")
result$multivariateNormality
# with Q-Q plot of the squared mahalanobis distance over chi-square
result <- mvn(data = X, mvnTest = "hz", multivariatePlot = "qq")
result$multivariateNormality
## Example 2: Board stiffness dataset (J-W, Ch. 4)  --------------------------------------------
# Four measures of stiffness (жесткость) of 30 boards are available. The first measure of stiffness is obtained
# by sending a shock wave down the board, the second measure is obtained by vibrating the board,
# and remaining are obtained from static tests.
stiff <- read.table('stiff.dat')
stiff
plot(stiff, asp = 1, pch = 19)
# Normality of the components
par(mfcol = c(2, 4))
for (i in 1:4) {
hist(
stiff[, i],
prob = T,
main = paste('Histogram of V', i, sep = ''),
xlab = paste('V', i, sep = '')
)
lines(900:2800,
dnorm(900:2800, mean(stiff[, i]), sd(stiff[, i])),
col = 'blue',
lty = 2)
qqnorm(stiff[, i], main = paste('QQplot of V', i, sep = ''))
qqline(stiff[, i])
print(shapiro.test(stiff[, i])$p)
}
par(mfcol = c(1, 1))
result <- mvn(data = stiff,
multivariatePlot = "qq",
covariance = FALSE)
result$multivariateNormality
### Let's try to identify and remove outliers:
M <- colMeans(stiff)
S <- cov(stiff)
d2 <- matrix(mahalanobis(stiff, M, S))
stiff_wo_outliers <- stiff[which(d2 <= 8),] # 8 - from plot, just avisual analys
result <- mvn(data = stiff_wo_outliers)
result$multivariateNormality
plot(stiff_wo_outliers, asp = 1, pch = 19)
# Normality of the components
par(mfcol = c(2, 4))
for (i in 1:4) {
hist(
stiff_wo_outliers[, i],
prob = T,
main = paste('Histogram of V', i, sep = ''),
xlab = paste('V', i, sep = '')
)
lines(900:2800,
dnorm(900:2800, mean(stiff_wo_outliers[, i]), sd(stiff_wo_outliers[, i])),
col = 'blue',
lty = 2)
qqnorm(stiff_wo_outliers[, i], main = paste('QQplot of V', i, sep = ''))
qqline(stiff_wo_outliers[, i])
print(shapiro.test(stiff_wo_outliers[, i])$p) # check that each feature came from Normal distribution
}
## Example with board stiffness dataset -------------------------------------------------------
stiff <- read.table('stiff.dat')
head(stiff)
dim(stiff)
n <- dim(stiff)[1]
p <- dim(stiff)[2]
plot(stiff, pch = 19)
# Normality test
mvn(stiff)$multivariateNormality
mvn(stiff_wo_outliers)$multivariateNormality
n <- dim(stiff_wo_outliers)[1]
p <- dim(stiff_wo_outliers)[2]
mu0   <- c(1850, 1750, 1500, 1700)
alpha <- 0.05
# 2) Compute the test statistics
x.mean   <- colMeans(stiff_wo_outliers)
x.cov    <- cov(stiff_wo_outliers)
x.invcov <- solve(x.cov)
x.T2     <- n * (x.mean-mu0) %*% x.invcov %*% (x.mean-mu0)
# 3a) Verify if the test statistics belongs to the acceptance region
cfr.fisher <- ((n - 1) * p / (n - p)) * qf(1 - alpha, p, n - p)
x.T2 < cfr.fisher # we accept H0 at 5%
# 3b) Compute the p-value
P <- 1 - pf(x.T2*(n-p)/((n-1)*p), p, n-p)
P
# Center:
x.mean
# Directions of the principal axes:
eigen(x.cov/n)$vectors
# Length of the semi-axes of the ellipse:
r <- sqrt(cfr.fisher)
r*sqrt(eigen(x.cov/n)$values)
T2 <- cbind(inf = x.mean - sqrt(cfr.fisher*diag(x.cov)/n),
center = x.mean,
sup = x.mean + sqrt(cfr.fisher*diag(x.cov)/n))
T2
# Plot of the simultaneous T2 intervals in the direction of X1,...,X4
matplot(1:4,1:4, pch='',ylim=range(stiff_wo_outliers), xlab='Variables', ylab='T2 for a component',
main='Simultaneous T2 conf. int. for the components')
for(i in 1:4) segments(i, T2[i,1], i, T2[i,3], lwd=3, col=i)
points(1:4, T2[,2], pch=16, col=1:4)
# Is mu0 inside the rectangular region?
# We add it to the plot
points(1:4, mu0, lwd=3, col='orange')
# Bonferroni intervals on the components of the mean
# with global level 95%
k <- p
cfr.t <- qt(1 - alpha/(k*2), n-1)
Bf <- cbind(inf = x.mean - cfr.t*sqrt(diag(x.cov)/n),
center = x.mean,
sup = x.mean + cfr.t*sqrt(diag(x.cov)/n))
T2
## Example with board stiffness dataset -------------------------------------------------------
stiff <- read.table('stiff.dat')
head(stiff)
dim(stiff)
n <- dim(stiff)[1]
p <- dim(stiff)[2]
plot(stiff, pch = 19)
# Normality test
mvn(stiff)$multivariateNormality
mvn(stiff_wo_outliers)$multivariateNormality
n <- dim(stiff_wo_outliers)[1]
p <- dim(stiff_wo_outliers)[2]
mu0   <- c(1850, 1750, 1500, 1700)
alpha <- 0.05
# 2) Compute the test statistics
x.mean   <- colMeans(stiff_wo_outliers)
x.cov    <- cov(stiff_wo_outliers)
x.invcov <- solve(x.cov)
# it's just dormula of T^2 statistic
x.T2     <- n * (x.mean-mu0) %*% x.invcov %*% (x.mean-mu0)
# 3a) Verify if the test statistics belongs to the acceptance region
cfr.fisher <- ((n - 1) * p / (n - p)) * qf(1 - alpha, p, n - p)
x.T2 < cfr.fisher # we accept H0 at 5%
# 3b) Compute the p-value
P <- 1 - pf(x.T2*(n-p)/((n-1)*p), p, n-p)
P
# Center:
x.mean
# Directions of the principal axes:
eigen(x.cov/n)$vectors
# Length of the semi-axes of the ellipse:
r <- sqrt(cfr.fisher)
r*sqrt(eigen(x.cov/n)$values)
T2 <- cbind(inf = x.mean - sqrt(cfr.fisher*diag(x.cov)/n),
center = x.mean,
sup = x.mean + sqrt(cfr.fisher*diag(x.cov)/n))
T2
# Plot of the simultaneous T2 intervals in the direction of X1,...,X4
matplot(1:4,1:4, pch='',ylim=range(stiff_wo_outliers), xlab='Variables', ylab='T2 for a component',
main='Simultaneous T2 conf. int. for the components')
for(i in 1:4) segments(i, T2[i,1], i, T2[i,3], lwd=3, col=i)
points(1:4, T2[,2], pch=16, col=1:4)
# Is mu0 inside the rectangular region?
# We add it to the plot
points(1:4, mu0, lwd=3, col='orange')
# Bonferroni intervals on the components of the mean
# with global level 95%
k <- p
cfr.t <- qt(1 - alpha/(k*2), n-1)
Bf <- cbind(inf = x.mean - cfr.t*sqrt(diag(x.cov)/n),
center = x.mean,
sup = x.mean + cfr.t*sqrt(diag(x.cov)/n))
Bf
plot.bonf <- function() {
# Let's do a plot
matplot(1:4, 1:4, pch='', ylim=range(stiff_wo_outliers), xlab='Variables',
ylab='Confidence intervals along a component', main='Confidence intervals')
for(i in 1:4) segments(i, T2[i,1], i, T2[i,3], lwd=2, col='grey35', lty=3)
points(1:4, T2[,1], pch='-', col='grey35')
points(1:4, T2[,3], pch='-', col='grey35')
for(i in 1:4) segments(i, Bf[i,1], i, Bf[i,3], lwd=2, col=i)
points(1:4, Bf[,2], pch=16, col=1:4)
points(1:4, Bf[,1], pch='-', col=1:4)
points(1:4, Bf[,3], pch='-', col=1:4)
# Is mu0 inside the Bonferroni confidence region?
# we add it to the plot
points(1:4, mu0, lwd=3, col='orange')
}
plot.bonf()
# Yes, it is, because it belongs to all the intervals along the components
# Yes, it is, because it belongs to all the intervals along the components
BF
Bf
T2
