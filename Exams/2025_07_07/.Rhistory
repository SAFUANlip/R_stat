x.mean
sqrt(cfr.fisher)
x.cov/n
k <- 4 # if we also wanted to plot for variances => k = 4
alpha <- 0.05
ICmean <- cbind(inf=x.mean - sqrt(diag(x.cov)/n) * qt(1 - alpha/(2*k), n-1),
center= x.mean,
sup= x.mean + sqrt(diag(x.cov)/n) * qt(1 - alpha/(2*k), n-1))
ICmean
mu0      <- c(0, 0) # H0, that difference is zero
x.mean   <- colMeans(data_difference_ref_wristband)
x.cov    <- cov(data_difference_ref_wristband)
x.invcov <- solve(x.cov)
n <- 100 # each group has 100 observations
p <- 2 # check two means on zero
x.T2 <- n * (x.mean-mu0) %*% x.invcov %*% (x.mean-mu0)
Pb <- 1-pf(x.T2*(n-p)/(p*(n-1)), p, n-p)
Pb # 6.884973e-05 < 0.05 (95%), so we can reject, that mean difference = 0
# mean under H0 (blue)
plot(data_difference_ref_wristband)
points(mu0[1], mu0[2], col='blue', pch=16)
# sample mean (black)
points(x.mean[1], x.mean[2], col='black', pch=16)
# we represent the confidence region of level 95%: where does mu0 fall?
alpha <- .05
data_difference <- data.frame(
ref_smart = smartwatch - reference,
ref_wristband = wristband - reference
)
boxplot(data_difference)
mu0      <- c(0, 0, 0, 0) # H0, that difference is zero
x.mean   <- colMeans(data_difference)
x.cov    <- cov(data_difference)
x.invcov <- solve(x.cov)
n <- 100 # each group has 100 observations
p <- 4 # check two means on zero
x.T2 <- n * (x.mean-mu0) %*% x.invcov %*% (x.mean-mu0)
Pb <- 1-pf(x.T2*(n-p)/(p*(n-1)), p, n-p)
Pb # 0.0002267289 < 0.05 (95%), so we can reject, that mean difference = 0
Characterize the confidence region of the previous test.
k <- 4 # we check 4 means => k = 4, if we also wanted to plot for variances => k = 8
alpha <- 0.05
ICmean <- cbind(inf=x.mean - sqrt(diag(x.cov)/n) * qt(1 - alpha/(2*k), n-1),
center= x.mean,
sup= x.mean + sqrt(diag(x.cov)/n) * qt(1 - alpha/(2*k), n-1))
ICmean
data_difference <- data.frame(
smart_ref = smartwatch - reference,
wristband_ref = wristband - reference
)
reference <-read.table("reference.txt", h=TRUE)
wristband <- read.table("wristband.txt", h=TRUE)
smartwatch <- read.table("smartwatch.txt", h=TRUE)
data_all <- data.frame(
hr_ref = reference$hr,
temp_ref = reference$temp,
hr_smart = smartwatch$hr,
temp_smart = smartwatch$temp,
hr_wr = wristband$hr,
temp_wr = wristband$temp
)
mvn(data_all)
data_difference <- data.frame(
smart_ref = smartwatch - reference,
wristband_ref = wristband - reference
)
boxplot(data_difference)
mu0      <- c(0, 0, 0, 0) # H0, that difference is zero
x.mean   <- colMeans(data_difference)
x.cov    <- cov(data_difference)
x.invcov <- solve(x.cov)
n <- 100 # each group has 100 observations
p <- 4 # check two means on zero
x.T2 <- n * (x.mean-mu0) %*% x.invcov %*% (x.mean-mu0)
Pb <- 1-pf(x.T2*(n-p)/(p*(n-1)), p, n-p)
Pb # 0.0002267289 < 0.05 (95%), so we can reject, that mean difference = 0
# mean under H0 (blue)
plot(data_difference)
points(mu0[1], mu0[2], col='blue', pch=16)
# sample mean (black)
points(x.mean[1], x.mean[2], col='black', pch=16)
k <- 4 # we check 4 means => k = 4, if we also wanted to plot for variances => k = 8
alpha <- 0.05
ICmean <- cbind(inf=x.mean - sqrt(diag(x.cov)/n) * qt(1 - alpha/(2*k), n-1),
center= x.mean,
sup= x.mean + sqrt(diag(x.cov)/n) * qt(1 - alpha/(2*k), n-1))
ICmean
reference <-read.table("reference.txt", h=TRUE)
wristband <- read.table("wristband.txt", h=TRUE)
smartwatch <- read.table("smartwatch.txt", h=TRUE)
data_all <- data.frame(
hr_ref = reference$hr,
temp_ref = reference$temp,
hr_smart = smartwatch$hr,
temp_smart = smartwatch$temp,
hr_wr = wristband$hr,
temp_wr = wristband$temp
)
mvn(data_all)
data_difference <- data.frame(
smart_ref = smartwatch - reference,
wristband_ref = wristband - reference
)
boxplot(data_difference)
mu0      <- c(0, 0, 0, 0) # H0, that difference is zero
x.mean   <- colMeans(data_difference)
x.cov    <- cov(data_difference)
x.invcov <- solve(x.cov)
n <- 100 # each group has 100 observations
p <- 4 # check two means on zero
x.T2 <- n * (x.mean-mu0) %*% x.invcov %*% (x.mean-mu0)
Pb <- 1-pf(x.T2*(n-p)/(p*(n-1)), p, n-p)
Pb # 0.0002267289 < 0.05 (95%), so we can reject, that mean difference = 0
# mean under H0 (blue)
plot(data_difference)
points(mu0[1], mu0[2], col='blue', pch=16)
# sample mean (black)
points(x.mean[1], x.mean[2], col='black', pch=16)
cfr.fisher <- (p*(n-1)/(n-p))*qf(1-alpha,p,n-p)
# c) Characterize the confidence region of the previous test.
# ???
alpha <- 0.05
cfr.fisher <- (p*(n-1)/(n-p))*qf(1-alpha,p,n-p)
cfr.fisher
summary(data_difference)
View(wristband)
mu0      <- c(0, 0, 0, 0) # H0, that difference is zero
x.mean   <- colMeans(data_difference)
x.cov    <- cov(data_difference)
x.invcov <- solve(x.cov)
n <- 100 # each group has 100 observations
p <- 4 # check two means on zero
x.T2 <- n * (x.mean-mu0) %*% x.invcov %*% (x.mean-mu0)
Pb <- 1-pf(x.T2*(n-p)/(p*(n-1)), p, n-p)
Pb # 0.0002267289 < 0.05 (95%), so we can reject, that mean difference = 0
View(data_difference)
t.test(data_difference$wristband_ref.hr)
t.test(data_difference$wristband_ref.temp)
t.test(data_difference$smart_ref.hr)
t.test(data_difference$smart_ref.temp)
t.test(data_difference$wristband_ref.hr) #p-value = 0.000608
library(nlmeU) ## --> for the dataset
library(nlme)
library(insight)
training <- read.table("FunctionalTraining.txt", h=TRUE)
training_lin <- data.frame(training,
lin = (training$Laptop_time + training$Phone_time/2)
)
lm_model <- lm(Views ~  Premium_account + lin + Social_connections + Fitness_level,
data=training_lin)
summary(lm_model)
confint(lm_model, "Social_connections", level=0.99)
training_lin
confint(lm_model, "Social_connections", level=0.99)
confint(lm_model, "Social_connections", level=0.99)
new <- data.frame(Fitness_level = 0, Language= "English", Premium_account=1,
Laptop_time=5, Phone_time=2, Social_connections=10,
lin=5+2/2)
# predict(lm_model, new, interval="confidence", level=1-0.05)  # доверительный интервал для E[Y | X]
predict(lm_model, new, interval="prediction", level=1-0.05) # prediction interval
lme_model <- lme(Views ~  Premium_account + lin + Social_connections + Fitness_level,
random = ~1|as.factor(Language),
data=training_lin)
summary(lme_model)
ranef(lme_model)
summary(lme_model)
# Highest expected Views
ranef(lme_model)
# Model that we had to submit (with varIdent heteroscedscity):
lme_model3 <- lme(Views ~  Premium_account + lin + Social_connections + Fitness_level,
random = ~1|as.factor(Language),
weights = varIdent(form =~1|as.factor(Fitness_level)),
data=training_lin)
summary(lme_model3)
anova(lme_model, lme_model2)
lme_model2 <- lme(Views ~  Premium_account + lin + Social_connections + Fitness_level,
random = ~1 + as.factor(Fitness_level)|as.factor(Language),
data=training_lin)
summary(lme_model2)
# Model that we had to submit (with varIdent heteroscedscity):
lme_model3 <- lme(Views ~  Premium_account + lin + Social_connections + Fitness_level,
random = ~1|as.factor(Language),
weights = varIdent(form =~1|as.factor(Fitness_level)),
data=training_lin)
summary(lme_model3)
anova(lme_model, lme_model2)
anova(lme_model, lme_model3)
library(fda)
temperature <- read.table("temperature.txt",h=TRUE)
View(temperature)
data <- t(temperature[, 1:25])
View(data)
stelvio <- read.table("2024_09_06/stelvio.txt", h=TRUE)
stelvio
stelvio <- read.table("2024_09_06/stelvio.txt", h=TRUE)
stelvio <- read.table("/2024_09_06/stelvio.txt", h=TRUE)
pwd
!pwd
stelvio <- read.table("Exams/2024_09_06/2024_09_06/stelvio.txt", h=TRUE)
help(create.bspline.basis)
ncol(data) # 126 points
nrow(data) # 365 points
m <- 3 # "using a basis of QUADRATIC B-splines", then we have to use norder = 4
nrow(data) # 25 points
basis <- create.bspline.basis(rangeval=c(0,25), nbasis=nbasis, norder=m)
basis <- create.bspline.basis(rangeval=c(0,25), norder=m)
basis$nbasis
abscissa <- seq(0,25,1)
functionalPar <- fdPar(fdobj=basis, Lfdobj=m-2, lambda=1) # Lfdobj=m-2 penalise second derivative
Xobs0 <- stelvio$altitude
Xobs0 <- data
Xss <- smooth.basis(abscissa, Xobs0, functionalPar)
abscissa
abscissa <- seq(0,24,1)
functionalPar <- fdPar(fdobj=basis, Lfdobj=m-2, lambda=1) # Lfdobj=m-2 penalise second derivative
Xobs0 <- data
Xss <- smooth.basis(abscissa, Xobs0, functionalPar)
Xss0 <- eval.fd(abscissa, Xss$fd, Lfd=0) # zero derivative (fit to data)
Xss1 <- eval.fd(abscissa, Xss$fd, Lfd=1) # first derivative (fit to first derivative)
Xss2 <- eval.fd(abscissa, Xss$fd, Lfd=2)
plot(abscissa, Xobs0, type = "l")
plot(basis)
plot(abscissa, Xss0, type = "l")
length(abscissa)
length(Xss0)
View(Xss)
plot(abscissa, Xss0, type = "l")
plot(abscissa, Xss$fd, type = "l")
length(Xss$fd)
plot(Xss$fd, type = "l")
plot(Xss, type = "l")
plot(Xss0, type = "l")
temperature <- read.table("temperature.txt",h=TRUE)
data <- t(temperature[, 1:25])
help(create.bspline.basis)
m <- 3 # "using a basis of QUADRATIC B-splines", then we have to use norder = 4
abscissa <- seq(0,24,1)
basis <- create.bspline.basis(rangeval=c(0,25), norder=m, breaks=)
basis <- create.bspline.basis(rangeval=c(0,25), norder=m, breaks=abscissa)
basis$nbasis
basis <- create.bspline.basis(rangeval=c(0,24), norder=m, breaks=abscissa)
functionalPar <- fdPar(fdobj=basis, Lfdobj=m-2, lambda=1) # Lfdobj=m-2 penalise second derivative
Xobs0 <- data
Xss <- smooth.basis(abscissa, Xobs0, functionalPar)
Xss0 <- eval.fd(abscissa, Xss$fd, Lfd=0) # zero derivative (fit to data)
Xss1 <- eval.fd(abscissa, Xss$fd, Lfd=1) # first derivative (fit to first derivative)
Xss2 <- eval.fd(abscissa, Xss$fd, Lfd=2)
plot(Xss0, type = "l")
plot(basis)
functionalPar <- fdPar(fdobj=basis, Lfdobj=m-2, lambda=1) # Lfdobj=m-2 penalise second derivative
Xobs0 <- data
Xss <- smooth.basis(abscissa, Xobs0, functionalPar)
Xss0 <- eval.fd(abscissa, Xss$fd, Lfd=0) # zero derivative (fit to data)
Xss1 <- eval.fd(abscissa, Xss$fd, Lfd=1) # first derivative (fit to first derivative)
Xss2 <- eval.fd(abscissa, Xss$fd, Lfd=2)
plot(Xss0, type = "l")
plot(basis)
length(abscissa)
plot(abscissa, Xss0, type = "l")
length(abscissa)
length(Xss$fd)
length(Xss)
length(Xss0)
plot(Xss$fd, type = "l")
plot(Xss$fd)
plot(Xss0)
plot(Xobs0)
plot(Xobs0, type = "l")
plot(data, type = "l")
matplot(data, type='l',main='Kwat consumption', xlab='Hours', ylab='365 days')
matplot(Xss0, type='l',main='Kwat consumption', xlab='Hours', ylab='365 days')
plot(Xss$fd, main='Smoothed data', xlab='Hours', ylab='365 days')
matplot(Xss0, type='l',main='Kwat consumption', xlab='Hours', ylab='365 days')
matplot(data, type='l',main='Kwat consumption', xlab='Hours', ylab='365 days')
View(Xss)
matplot(Xss$fd, main='Smoothed data', xlab='Hours', ylab='365 days')
plot(Xss$fd, main='Smoothed data', xlab='Hours', ylab='365 days')
functionalPar <- fdPar(fdobj=basis, Lfdobj=1, lambda=1) # Lfdobj=m-2 penalise second derivative
Xobs0 <- data
Xss <- smooth.basis(abscissa, Xobs0, functionalPar)
Xss0 <- eval.fd(abscissa, Xss$fd, Lfd=0) # zero derivative (fit to data)
Xss1 <- eval.fd(abscissa, Xss$fd, Lfd=1) # first derivative (fit to first derivative)
Xss2 <- eval.fd(abscissa, Xss$fd, Lfd=2)
matplot(data, type='l',main='Kwat consumption', xlab='Hours', ylab='365 days')
plot(Xss$fd, main='Smoothed data', xlab='Hours', ylab='365 days') # expected picture
temperature <- read.table("temperature.txt",h=TRUE)
data <- t(temperature[, 1:25])
help(create.bspline.basis)
m <- 3 # "using a basis of QUADRATIC B-splines", then we have to use norder = 4
nrow(data) # 25 points
abscissa <- seq(0,24,1)
basis <- create.bspline.basis(rangeval=c(0,24), norder=m, breaks=abscissa)
functionalPar <- fdPar(fdobj=basis, Lfdobj=1, lambda=1) # Lfdobj=m-2 penalise second derivative
Xobs0 <- data
Xss <- smooth.basis(abscissa, Xobs0, functionalPar)
Xss0 <- eval.fd(abscissa, Xss$fd, Lfd=0) # zero derivative (fit to data)
Xss1 <- eval.fd(abscissa, Xss$fd, Lfd=1) # first derivative (fit to first derivative)
Xss2 <- eval.fd(abscissa, Xss$fd, Lfd=2)
matplot(data, type='l',main='Kwat consumption', xlab='Hours', ylab='365 days')
plot(Xss$fd, main='Smoothed data', xlab='Hours', ylab='365 days') # expected picture
matplot(data, type='l',main='Temperature source data', xlab='Hours', ylab='365 days')
plot(Xss$fd, main='Smoothed data', xlab='Hours', ylab='365 days') # expected picture
Xss$fd
View(data)
matplot(Xss0, type='l',main='Fit to data', xlab='Hours', ylab='365 days')
matplot(Xss1, type='l',main='Fit to data 1-st derivative', xlab='Hours', ylab='365 days')
matplot(Xss2, type='l',main='Fit to data 2-nd derivative', xlab='Hours', ylab='365 days')
plot(abscissa, Xss1, main='Smoothed data', xlab='Hours', ylab='365 days') # expected picture
plot(Xss1, main='Smoothed data', xlab='Hours', ylab='365 days') # expected picture
matplot(Xss1, main='Smoothed data', xlab='Hours', ylab='365 days') # expected picture
# GCV
gcv <- Xss$gcv
gcv # 1490.361
mean(gcv) # 1490.361
# Number of splines
basis$nbasis
basis <- create.bspline.basis(rangeval=c(0,24), norder=m, breaks=abscissa)
# Number of splines
basis$nbasis
# Approximate dimension of the space in which the smoothed curves live
df <- Xss$df   #  number of parameters (so dimension of space)
df  # 14.31518
# Number of splines
basis$nbasis
pca_W <- pca.fd(Xss$fd, nharm=5, centerfns=TRUE)
plot(pca_W$values[1:35],xlab='j',ylab='Eigenvalues')
plot(cumsum(pca_W$values)[1:35]/sum(pca_W$values), xlab='j', ylab='CPV', ylim=c(0.8,1))
summary(pca_W)
pca_W
# we have 35 data, (features), so we can not plot more principal components
pca_W$values
cumsum(pca_W$values)[1:35]/sum(pca_W$values) # we have 13 PC, because we used basis of 13 function
pca_W$values[2]/sum(pca_W$values) # 0.03984729
temperature <- read.table("temperature.txt",h=TRUE)
data <- t(temperature[, 1:25])
help(create.bspline.basis)
m <- 3 # "using a basis of QUADRATIC B-splines", then we have to use norder = 4
nrow(data) # 25 points
abscissa <- seq(0,24,1)
basis <- create.bspline.basis(rangeval=c(0,24), norder=m, breaks=abscissa)
functionalPar <- fdPar(fdobj=basis, Lfdobj=1, lambda=1) # Lfdobj=1  penalise second derivative ? not sure, maybe m-1?
Xobs0 <- data
Xss <- smooth.basis(abscissa, Xobs0, functionalPar)
Xss0 <- eval.fd(abscissa, Xss$fd, Lfd=0) # zero derivative (fit to data)
Xss1 <- eval.fd(abscissa, Xss$fd, Lfd=1) # first derivative (fit to first derivative)
Xss2 <- eval.fd(abscissa, Xss$fd, Lfd=2)
matplot(data, type='l',main='Temperature source data', xlab='Hours', ylab='365 days')
plot(Xss$fd, main='Smoothed data', xlab='Hours', ylab='365 days') # expected picture (I guess)
matplot(Xss0, type='l',main='Fit to data', xlab='Hours', ylab='365 days')
# Number of splines
basis$nbasis # 26
# GCV
gcv <- Xss$gcv
mean(gcv) # 1.174517
# Approximate dimension of the space in which the smoothed curves live
df <- Xss$df   #  number of parameters (so dimension of space)
df  # 9.833603 ~ 10
pca_W <- pca.fd(Xss$fd, nharm=5, centerfns=TRUE)
plot(pca_W$values[1:35],xlab='j',ylab='Eigenvalues')
plot(cumsum(pca_W$values)[1:35]/sum(pca_W$values), xlab='j', ylab='CPV', ylim=c(0.8,1))
# we have 35 data, (features), so we can not plot more principal components
pca_W$values
cumsum(pca_W$values)[1:35]/sum(pca_W$values) # we have 13 PC, because we used basis of 13 function
cumsum(pca_W$values)[1:36]/sum(pca_W$values) # we have 13 PC, because we used basis of 13 function
plot(pca_W$values[1:26],xlab='j',ylab='Eigenvalues')
plot(cumsum(pca_W$values)[1:26]/sum(pca_W$values), xlab='j', ylab='CPV', ylim=c(0.8,1))
# we have 26 data, (features - nbasis), so we can not plot more principal components
pca_W$values
cumsum(pca_W$values)[1:26]/sum(pca_W$values) # we have 13 PC, because we used basis of 13 function
pca_W$values[2]/sum(pca_W$values) # 0.03984729
pca_W$values[1]/sum(pca_W$values) # 0.03984729
pca_W$values[2]/sum(pca_W$values) # 0.03984729
0.9820061 - 0.9332788
# c) Provide a plot showing the effect of the second principal component.
layout(cbind(1,2))
plot(pca_W$harmonics[1,],col=1,ylab='FPC1',ylim=c(0.0,0.4))
abline(h=0,lty=2)
plot(pca_W$harmonics[2,],col=2,ylab='FPC2',ylim=c(-0.5,0.5))
# c) Provide a plot showing the effect of the second principal component.
# plot of the FPCs as perturbation of the mean
media <- mean.fd(data_W.fd)
plot(media,lwd=2,ylim=c(0,60),ylab='temperature',main='FPC1')
# c) Provide a plot showing the effect of the second principal component.
# plot of the FPCs as perturbation of the mean
media <- mean.fd(data_W.fd)
# c) Provide a plot showing the effect of the second principal component.
# plot of the FPCs as perturbation of the mean
media <- mean.fd(Xss$fd)
plot(media,lwd=2,ylim=c(0,60),ylab='temperature',main='FPC1')
lines(media+pca_W$harmonics[1,]*sqrt(pca_W$values[1]), col=2)
lines(media-pca_W$harmonics[1,]*sqrt(pca_W$values[1]), col=3)
plot(media,lwd=2,ylim=c(0,60),ylab='temperature',main='FPC2')
lines(media+pca_W$harmonics[2,]*sqrt(pca_W$values[2]), col=2)
lines(media-pca_W$harmonics[2,]*sqrt(pca_W$values[2]), col=3)
# USE THIS TO EXPLAIN COMPONENTS
# Command of the library fda that automatically does these plots
par(mfrow=c(1,2))
plot(pca_W, nx=100, pointplot=TRUE, harm=c(1,2), expand=0, cycle=FALSE)
plot(Xss0, type='l',main='Fit to data', xlab='Hours', ylab='365 days')
plot(Xss0,main='Fit to data', xlab='Hours', ylab='365 days')
Xss0
plot.fd(Xss0)
plot.fd(Xss)
matplot(Xss0, type='l',main='Fit to data', xlab='Hours', ylab='365 days')
plot(Xss0,main='Fit to data', xlab='Hours', ylab='365 days')
# d) Is the representation given by the first principal component satisfying for distinguishing seasons? Support your
# answer with a plot.
pca_W$scores
View(pca_W)
plot(pca_W$scores[,1])
pca_W$scores[,1]
View(temperature)
season <-temperature$season
plot(pca_W$scores[,1] ~ season)
plot(pca_W$scores[,1] ~ season)
season
matplot(pca_W$scores[,1] ~ season)
matplot(pca_W$scores[,1])
length(pca_W$scores[,1])
length(season)
matplot(pca_W$scores[,1])
scores <- pca_W$scores
plot(scores[, 1], scores[, 2], col = ifelse(load$daytype == "Working day", "blue", "red"),
pch = 19, xlab = "PC1", ylab = "PC2", main = "Scores of First Two Principal Components")
plot(scores[, 1], scores[, 2], col = season,
pch = 19, xlab = "PC1", ylab = "PC2", main = "Scores of First Two Principal Components")
plot(scores[, 1], scores[, 2], col = as.factor(season),
pch = 19, xlab = "PC1", ylab = "PC2", main = "Scores of First Two Principal Components")
legend("topright", legend = c("Working day", "Holiday"), col = c("blue", "red"), pch = 19)
legend("topright", legend = as.factor(season), col = c("blue", "red"), pch = 19)
as.factor(season)
as.factor(season)$levels
as.factor(season)$Levels
as.factor(season)
legend("topright", legend = c("Autumn", "Spring", "Summer", "Winter"), col = c("blue", "red"), pch = 19)
scores <- pca_W$scores
plot(scores[, 1], scores[, 2], col = as.factor(season),
pch = 19, xlab = "PC1", ylab = "PC2", main = "Scores of First Two Principal Components")
legend("topright", legend = c("Autumn", "Spring", "Summer", "Winter"), col = as.factor(season), pch = 19)
scores <- pca_W$scores
plot(scores[, 1], scores[, 2],
pch = 19, xlab = "PC1", ylab = "PC2", main = "Scores of First Two Principal Components")
legend("topright", legend = c("Autumn", "Spring", "Summer", "Winter"), col = as.factor(season), pch = 19)
scores <- pca_W$scores
plot(scores[, 1], scores[, 2], col = as.factor(season),
pch = 19, xlab = "PC1", ylab = "PC2", main = "Scores of First Two Principal Components")
legend("topright", legend = c("Autumn", "Spring", "Summer", "Winter"), col = as.factor(season), pch = 19)
levels(as.factor(season))
legend("topright", legend = c("Autumn", "Spring", "Summer", "Winter"), col = levels(as.factor(season)), pch = 19)
legend("topright", legend = c("Autumn", "Spring", "Summer", "Winter"), col = as.factor(levels(as.factor(season))), pch = 19)
scores <- pca_W$scores
plot(scores[, 1], scores[, 2], col = as.factor(season),
pch = 19, xlab = "PC1", ylab = "PC2", main = "Scores of First Two Principal Components")
legend("topright", legend = c("Autumn", "Spring", "Summer", "Winter"), col = as.factor(levels(as.factor(season))), pch = 19)
plot(scores[, 1])
plot(scores[, 1] ~ as.factor(season))
matplot(scores[, 1] ~ as.factor(season))
plot(scores[, 1] ~ as.factor(season))
plot(scores[, 2] ~ as.factor(season))
plot(scores[, 1] ~ as.factor(season)) # by PC1 we see
temperature <- read.table("temperature.txt",h=TRUE)
season <-temperature$season
data <- t(temperature[, 1:25])
help(create.bspline.basis)
m <- 3 # "using a basis of QUADRATIC B-splines", then we have to use norder = 4
nrow(data) # 25 points
abscissa <- seq(0,24,1)
basis <- create.bspline.basis(rangeval=c(0,24), norder=m, breaks=abscissa)
functionalPar <- fdPar(fdobj=basis, Lfdobj=1, lambda=1) # Lfdobj=1  penalise second derivative ? not sure, maybe m-1?
Xobs0 <- data
Xss <- smooth.basis(abscissa, Xobs0, functionalPar)
Xss0 <- eval.fd(abscissa, Xss$fd, Lfd=0) # zero derivative (fit to data)
Xss1 <- eval.fd(abscissa, Xss$fd, Lfd=1) # first derivative (fit to first derivative)
Xss2 <- eval.fd(abscissa, Xss$fd, Lfd=2)
matplot(data, type='l',main='Temperature source data', xlab='Hours', ylab='365 days')
plot(Xss$fd, main='Smoothed data', xlab='Hours', ylab='365 days') # expected picture (I guess)
matplot(Xss0, type='l',main='Fit to data', xlab='Hours', ylab='365 days')
# Number of splines
basis$nbasis # 26
# GCV
gcv <- Xss$gcv
mean(gcv) # 1.174517
# Approximate dimension of the space in which the smoothed curves live
df <- Xss$df   #  number of parameters (so dimension of space)
df  # 9.833603 ~ 10
pca_W <- pca.fd(Xss$fd, nharm=5, centerfns=TRUE)
plot(pca_W$values[1:26],xlab='j',ylab='Eigenvalues')
plot(cumsum(pca_W$values)[1:26]/sum(pca_W$values), xlab='j', ylab='CPV', ylim=c(0.8,1))
# we have 26 data, (features - nbasis), so we can not plot more principal components
pca_W$values
cumsum(pca_W$values)[1:26]/sum(pca_W$values) # we have 13 PC, because we used basis of 13 function
pca_W$values[2]/sum(pca_W$values) # 0.04872728 ~ 0.049
# c) Provide a plot showing the effect of the second principal component.
# plot of the FPCs as perturbation of the mean
media <- mean.fd(Xss$fd)
plot(media,lwd=2,ylim=c(0,60),ylab='temperature',main='FPC1')
lines(media+pca_W$harmonics[1,]*sqrt(pca_W$values[1]), col=2)
lines(media-pca_W$harmonics[1,]*sqrt(pca_W$values[1]), col=3)
plot(media,lwd=2,ylim=c(0,60),ylab='temperature',main='FPC2')
lines(media+pca_W$harmonics[2,]*sqrt(pca_W$values[2]), col=2)
lines(media-pca_W$harmonics[2,]*sqrt(pca_W$values[2]), col=3)
# USE THIS TO EXPLAIN COMPONENTS
# Command of the library fda that automatically does these plots
par(mfrow=c(1,2))
plot(pca_W, nx=100, pointplot=TRUE, harm=c(1,2), expand=0, cycle=FALSE)
scores <- pca_W$scores
plot(scores[, 1], scores[, 2], col = as.factor(season),
pch = 19, xlab = "PC1", ylab = "PC2", main = "Scores of First Two Principal Components")
legend("topright", legend = c("Autumn", "Spring", "Summer", "Winter"), col = as.factor(levels(as.factor(season))), pch = 19)
plot(scores[, 1] ~ as.factor(season)) # by PC1 we see difference among Summer, Winter and Autumn wiht Spring
plot(scores[, 2] ~ as.factor(season)) # by PC2 it's difficlut to ifnd difference among seasons
# e) Could we successfully classify seasons based on the representation given by the second principal component?
