optimize(f=misclass, lower=min(sardine), upper=max(sardine))
R   <- optimize(f=misclass, lower=min(sardine), upper=max(sardine))$minimum
AER <- optimize(f=misclass, lower=min(sardine), upper=max(sardine))$objective
# check
AER == 0.25*(1 - pnorm(R, mean(sardinai), SD)) + 0.75*pnorm(R, mean(sardinaa), SD)
# some plots
specie <- factor(rep(c('Atlantica', 'Iberica'), each=500))
lunghezza <- c(sardine[[1]], sardine[[2]])
fit <- lda(specie ~ lunghezza, prior=c(0.75, 0.25))
x <- data.frame(lunghezza=seq(min(sardine), max(sardine), 0.05))
LDA <- predict(fit, x)$posterior[,2] # classe iberica
x11()
par(mfrow=c(2,1))
plot(x[,1], 0.25*(dnorm(x[,1], MI, SD)), type='l', col='red', lty=1, xlab='x', ylab='density * prior', ylim=c(0,0.6))
lines(x[,1], 0.75*(dnorm(x[,1], MA, SD)), type='l', col='blue', lty=1, xlab='x', ylab='density * prior')
abline(v=R, lty=2)
points(sardinaa, rep(0, 500), pch=3, col='blue')
points(sardinai, rep(0, 500), pch=3, col='red')
legend(7,.5,legend=c('Atlantic','Iberian'),fill=c('blue','red'),cex=.7)
plot(x[,1], LDA, type='l', col='red', lty=1, xlab='x', ylab='estimated posterior')# rosso = iberica
lines(x[,1], 1 - LDA, type='l', col='blue', lty=1, xlab='x', ylab='estimated posterior')# blu = atlantica
abline(h = 0.5)
abline(v=R, lty=2)
points(sardinaa, rep(0, 500), pch=3, col='blue')
points(sardinai, rep(0, 500), pch=3, col='red')
dev.off()
sardine <- read.table('sardine.txt', header=T)
head(sardine)
# a) normality test - (shapiro for p=1), ---------------------------------------
# mean equality - anova, t.test,
# homogenity - var.test, bartlett.test
help(t.test)
Atalantica_data <- sardine$Atlantica
Iberica_data <- sardine$Iberica
help(shapiro.test)
normality_test_Atalantica <- shapiro.test(Atalantica_data)
normality_test_Iberica <- shapiro.test(Iberica_data)
# Normality
normality_test_Atalantica$p.value # p-value > 0.05 can not reject H0 of normality
normality_test_Iberica$p.value # p-value > 0.05 can not reject H0 of normality
data_all <- c(Atalantica_data, Iberica_data)
labels_all <- vector(length = 1000)
Atalantica_index <- which(labels_all == "Atlantica")
Iberica_index <- which(labels_all == "Iberica")
for (i in 1:length(labels_all)){
if (i <= 500){
labels_all[i] <- "Atlantica"
}
else{
labels_all[i] <- "Iberica"
}
}
# equality of variances
bartlett.test(data_all ~ labels_all) # p-value > 0.05 => so we can not reject H0 of equal variances
var.test(data_all ~ labels_all) # p-value > 0.05 => so we can not reject H0 of equal variances
# equality of means
t.test(data_all ~ labels_all) # p-value < 0.05, so we can reject H0 of equal means
fit.aov <- aov(data_all ~ labels_all) # p-value < 0.05, so we can reject H0 of equal means
# variacne equal, normal distributed -> can perform LDA, for QDA (don't need variance equality)
# For FDA don't need normality
# b) If asks minimise misclassification -> it have to be LDA or QDA ------------
lda_model <- lda(as.matrix(data_all), labels_all, prior=c(75, 25)/100)
lda_model
# Projection of LD1 ------------------------------------------------------------
# 1. Get direction, where we have to project our data, to maximize
# variability between/variability within - ? as in FDA?
w <- lda_model$scaling[, 1] # solve(S) %*% (M1 - M0)
# 2. Проецируем все точки
lda_proj <- as.vector(as.matrix(data_all) %*% w)
# 3. Получаем проекции по группам
proj_atlantica <- lda_proj[Atalantica_index]
proj_iberica <- lda_proj[Iberica_index]
# 4. Оценим среднее и дисперсию на проекции
M_atlantica_proj <- mean(proj_atlantica)
M_iberica_proj <- mean(proj_iberica)
S_atlantica_proj <- cov(as.matrix(proj_atlantica))
S_iberica_proj <- cov(as.matrix(proj_iberica))
S_proj <- ((500-1) * S_atlantica_proj + (500-1) * S_iberica_proj) / (500 + 500 - 2)  # т.к. на проекции — одно измерение
# 5. Plot graphs
x <- seq(min(lda_proj), max(lda_proj), length.out = 500)
par(mfrow = c(2,1))
# Gaussian
plot(
x,
0.75 * dnorm(x, M_atlantica_proj, sqrt(S_proj)),
type = 'l',
col = 'blue',
ylab = expression(paste('estimated ', p[i] * f[i], '(x)')),
main = 'LDA (projection)'
)
# 5. Plot graphs
x <- seq(min(lda_proj), max(lda_proj), length.out = 500)
par(mfrow = c(2,1))
# Gaussian
plot(
x,
0.75 * dnorm(x, M_atlantica_proj, sqrt(S_proj)),
type = 'l',
col = 'blue',
ylab = expression(paste('estimated ', p[i] * f[i], '(x)')),
main = 'LDA (projection)'
)
lines(x, 0.25 * dnorm(x, M_iberica_proj, sqrt(S_proj)), col = 'red')
lda_model
# Projection of LD1 ------------------------------------------------------------
# 1. Get direction, where we have to project our data, to maximize
# variability between/variability within - ? as in FDA?
w <- lda_model$scaling[, 1] # solve(S) %*% (M1 - M0)
# 2. Проецируем все точки
lda_proj <- as.vector(as.matrix(data_all) %*% w)
lda_proj
# 3. Получаем проекции по группам
proj_atlantica <- lda_proj[Atalantica_index]
proj_iberica <- lda_proj[Iberica_index]
labels_all
Atalantica_index <- which(labels_all == "Atlantica")
Iberica_index <- which(labels_all == "Iberica")
sardine <- read.table('sardine.txt', header=T)
head(sardine)
# a) normality test - (shapiro for p=1), ---------------------------------------
# mean equality - anova, t.test,
# homogenity - var.test, bartlett.test
help(t.test)
Atalantica_data <- sardine$Atlantica
Iberica_data <- sardine$Iberica
help(shapiro.test)
normality_test_Atalantica <- shapiro.test(Atalantica_data)
normality_test_Iberica <- shapiro.test(Iberica_data)
# Normality
normality_test_Atalantica$p.value # p-value > 0.05 can not reject H0 of normality
normality_test_Iberica$p.value # p-value > 0.05 can not reject H0 of normality
data_all <- c(Atalantica_data, Iberica_data)
labels_all <- vector(length = 1000)
Atalantica_index <- which(labels_all == "Atlantica")
data_all <- c(Atalantica_data, Iberica_data)
labels_all <- vector(length = 1000)
for (i in 1:length(labels_all)){
if (i <= 500){
labels_all[i] <- "Atlantica"
}
else{
labels_all[i] <- "Iberica"
}
}
Atalantica_index <- which(labels_all == "Atlantica")
Iberica_index <- which(labels_all == "Iberica")
# equality of variances
bartlett.test(data_all ~ labels_all) # p-value > 0.05 => so we can not reject H0 of equal variances
var.test(data_all ~ labels_all) # p-value > 0.05 => so we can not reject H0 of equal variances
# equality of means
t.test(data_all ~ labels_all) # p-value < 0.05, so we can reject H0 of equal means
fit.aov <- aov(data_all ~ labels_all) # p-value < 0.05, so we can reject H0 of equal means
lda_model <- lda(as.matrix(data_all), labels_all, prior=c(75, 25)/100)
lda_model
# Projection of LD1 ------------------------------------------------------------
# 1. Get direction, where we have to project our data, to maximize
# variability between/variability within - ? as in FDA?
w <- lda_model$scaling[, 1] # solve(S) %*% (M1 - M0)
# 2. Проецируем все точки
lda_proj <- as.vector(as.matrix(data_all) %*% w)
# 3. Получаем проекции по группам
proj_atlantica <- lda_proj[Atalantica_index]
proj_iberica <- lda_proj[Iberica_index]
# 4. Оценим среднее и дисперсию на проекции
M_atlantica_proj <- mean(proj_atlantica)
M_iberica_proj <- mean(proj_iberica)
S_atlantica_proj <- cov(as.matrix(proj_atlantica))
S_iberica_proj <- cov(as.matrix(proj_iberica))
S_proj <- ((500-1) * S_atlantica_proj + (500-1) * S_iberica_proj) / (500 + 500 - 2)  # т.к. на проекции — одно измерение
# 5. Plot graphs
x <- seq(min(lda_proj), max(lda_proj), length.out = 500)
par(mfrow = c(2,1))
# Gaussian
plot(
x,
0.75 * dnorm(x, M_atlantica_proj, sqrt(S_proj)),
type = 'l',
col = 'blue',
ylab = expression(paste('estimated ', p[i] * f[i], '(x)')),
main = 'LDA (projection)'
)
lines(x, 0.25 * dnorm(x, M_iberica_proj, sqrt(S_proj)), col = 'red')
points(proj_atlantica, rep(0, length(proj_atlantica)), col = 'blue', pch = 16)
points(proj_iberica, rep(0, length(proj_iberica)), col = 'red', pch = 16)
legend("topright", legend=c("Atlantica", "Iberica"), col=c("blue", "red"), lty=1)
# posterior probability
posterior_atlantica <- 0.75 * dnorm(x, M_atlantica_proj, sqrt(S_proj)) / (
0.75 * dnorm(x, M_atlantica_proj, sqrt(S_proj)) + 0.25 * dnorm(x, M_iberica_proj, sqrt(S_proj))
)
posterior_iberica <- 1 - posterior_atlantica
plot(x, posterior_atlantica, type = 'l', col = 'blue', ylab = 'estimated posterior')
lines(x, posterior_iberica, col = 'red')
legend("topright", legend=c("P(Class 0 | x)", "P(Class 1 | x)"), col=c("blue", "red"), lty=1)
par(mfrow = c(1,1))
sardine <- read.table('sardine.txt', header=T)
head(sardine)
# question a)
sardinaa <- sardine[[1]]
sardinai <- sardine[[2]]
shapiro.test(sardinaa)
shapiro.test(sardinai)
var.test(sardinaa, sardinai)
t.test(sardinaa, sardinai, var.eq=T)
MA <- mean(sardinaa)
MI <- mean(sardinai)
SD <- sqrt((var(sardinaa) + var(sardinai))/2)
# Analitically
misclass <- function(x){
0.25*(1 - pnorm(x, MI, SD)) + 0.75*pnorm(x, MA, SD)
}
optimize(f=misclass, lower=min(sardine), upper=max(sardine))
R   <- optimize(f=misclass, lower=min(sardine), upper=max(sardine))$minimum
AER <- optimize(f=misclass, lower=min(sardine), upper=max(sardine))$objective
# check
AER == 0.25*(1 - pnorm(R, mean(sardinai), SD)) + 0.75*pnorm(R, mean(sardinaa), SD)
# some plots
specie <- factor(rep(c('Atlantica', 'Iberica'), each=500))
lunghezza <- c(sardine[[1]], sardine[[2]])
fit <- lda(specie ~ lunghezza, prior=c(0.75, 0.25))
x <- data.frame(lunghezza=seq(min(sardine), max(sardine), 0.05))
LDA <- predict(fit, x)$posterior[,2] # classe iberica
x11()
par(mfrow=c(2,1))
plot(x[,1], 0.25*(dnorm(x[,1], MI, SD)), type='l', col='red', lty=1, xlab='x', ylab='density * prior', ylim=c(0,0.6))
lines(x[,1], 0.75*(dnorm(x[,1], MA, SD)), type='l', col='blue', lty=1, xlab='x', ylab='density * prior')
abline(v=R, lty=2)
points(sardinaa, rep(0, 500), pch=3, col='blue')
points(sardinai, rep(0, 500), pch=3, col='red')
legend(7,.5,legend=c('Atlantic','Iberian'),fill=c('blue','red'),cex=.7)
plot(x[,1], LDA, type='l', col='red', lty=1, xlab='x', ylab='estimated posterior')# rosso = iberica
lines(x[,1], 1 - LDA, type='l', col='blue', lty=1, xlab='x', ylab='estimated posterior')# blu = atlantica
abline(h = 0.5)
abline(v=R, lty=2)
points(sardinaa, rep(0, 500), pch=3, col='blue')
points(sardinai, rep(0, 500), pch=3, col='red')
dev.off()
# Compute the APER
prior <- c(0.75,0.25)
G <- 2
misc <- table(classe.vera=specie, classe.allocata=predict(fit)$class)
misc
APER <- 0
for(g in 1:G)
APER <- APER + sum(misc[g,-g])/sum(sum(misc[g,])) * prior[g]
APER
AER
R
# c)
predictions <- predict(lda_model, data_all)
data_all
# c)
predictions <- predict(lda_model, data_all[1])
View(predictions)
View(predictions)
# c)
predictions <- predict(lda_model, as.matrix(data_all))
# c)
predictions <- predict(lda_model, as.matrix(data_all))$class
predictions
# Confusion matrix components
TP_lda <- sum(predictions == "Atlantica" & labels == "Atlantica")
FP_lda <- sum(predictions == "Atlantica" & labels == "Iberica")
labels == "Atlantica"
predictions == "Atlantica"
# Confusion matrix components
TP_lda <- sum(predictions == "Atlantica" & labels_all == "Atlantica")
FP_lda <- sum(predictions == "Atlantica" & labels_all == "Iberica")
FN_lda <- sum(predictions == "Iberica" & labels_all == "Atlantica")
TN_lda <- sum(predictions == "Iberica" & labels_all == "Iberica")
AER <-
lda_model
AER <-
lda_model
AER <-
lda_model
lda_model
AER <- 0.75 * FN_lda/500 + 0.25 * FP_lda/500
AER
AER
# check
AER == 0.25*(1 - pnorm(R, mean(sardinai), SD)) + 0.75*pnorm(R, mean(sardinaa), SD)
# check
AER == 0.25*(1 - pnorm(R, mean(sardinai), SD)) + 0.75*pnorm(R, mean(sardinaa), SD)
sardine <- read.table('sardine.txt', header=T)
head(sardine)
# question a)
sardinaa <- sardine[[1]]
sardinai <- sardine[[2]]
shapiro.test(sardinaa)
shapiro.test(sardinai)
var.test(sardinaa, sardinai)
t.test(sardinaa, sardinai, var.eq=T)
MA <- mean(sardinaa)
MI <- mean(sardinai)
SD <- sqrt((var(sardinaa) + var(sardinai))/2)
# Analitically
misclass <- function(x){
0.25*(1 - pnorm(x, MI, SD)) + 0.75*pnorm(x, MA, SD)
}
optimize(f=misclass, lower=min(sardine), upper=max(sardine))
R   <- optimize(f=misclass, lower=min(sardine), upper=max(sardine))$minimum
AER <- optimize(f=misclass, lower=min(sardine), upper=max(sardine))$objective
# check
AER == 0.25*(1 - pnorm(R, mean(sardinai), SD)) + 0.75*pnorm(R, mean(sardinaa), SD)
# some plots
specie <- factor(rep(c('Atlantica', 'Iberica'), each=500))
lunghezza <- c(sardine[[1]], sardine[[2]])
fit <- lda(specie ~ lunghezza, prior=c(0.75, 0.25))
x <- data.frame(lunghezza=seq(min(sardine), max(sardine), 0.05))
LDA <- predict(fit, x)$posterior[,2] # classe iberica
x11()
par(mfrow=c(2,1))
plot(x[,1], 0.25*(dnorm(x[,1], MI, SD)), type='l', col='red', lty=1, xlab='x', ylab='density * prior', ylim=c(0,0.6))
lines(x[,1], 0.75*(dnorm(x[,1], MA, SD)), type='l', col='blue', lty=1, xlab='x', ylab='density * prior')
abline(v=R, lty=2)
points(sardinaa, rep(0, 500), pch=3, col='blue')
points(sardinai, rep(0, 500), pch=3, col='red')
legend(7,.5,legend=c('Atlantic','Iberian'),fill=c('blue','red'),cex=.7)
plot(x[,1], LDA, type='l', col='red', lty=1, xlab='x', ylab='estimated posterior')# rosso = iberica
lines(x[,1], 1 - LDA, type='l', col='blue', lty=1, xlab='x', ylab='estimated posterior')# blu = atlantica
abline(h = 0.5)
abline(v=R, lty=2)
points(sardinaa, rep(0, 500), pch=3, col='blue')
points(sardinai, rep(0, 500), pch=3, col='red')
dev.off()
# Compute the APER
prior <- c(0.75,0.25)
G <- 2
misc <- table(classe.vera=specie, classe.allocata=predict(fit)$class)
misc
APER <- 0
for(g in 1:G)
APER <- APER + sum(misc[g,-g])/sum(sum(misc[g,])) * prior[g]
APER
AER
sardine <- read.table('sardine.txt', header=T)
head(sardine)
# a) normality test - (shapiro for p=1), ---------------------------------------
# mean equality - anova, t.test,
# homogenity - var.test, bartlett.test
help(t.test)
Atalantica_data <- sardine$Atlantica
Iberica_data <- sardine$Iberica
help(shapiro.test)
normality_test_Atalantica <- shapiro.test(Atalantica_data)
normality_test_Iberica <- shapiro.test(Iberica_data)
# Normality
normality_test_Atalantica$p.value # p-value > 0.05 can not reject H0 of normality
normality_test_Iberica$p.value # p-value > 0.05 can not reject H0 of normality
data_all <- c(Atalantica_data, Iberica_data)
labels_all <- vector(length = 1000)
for (i in 1:length(labels_all)){
if (i <= 500){
labels_all[i] <- "Atlantica"
}
else{
labels_all[i] <- "Iberica"
}
}
Atalantica_index <- which(labels_all == "Atlantica")
Iberica_index <- which(labels_all == "Iberica")
# equality of variances
bartlett.test(data_all ~ labels_all) # p-value > 0.05 => so we can not reject H0 of equal variances
var.test(data_all ~ labels_all) # p-value > 0.05 => so we can not reject H0 of equal variances
# equality of means
t.test(data_all ~ labels_all) # p-value < 0.05, so we can reject H0 of equal means
fit.aov <- aov(data_all ~ labels_all) # p-value < 0.05, so we can reject H0 of equal means
lda_model <- lda(as.matrix(data_all), labels_all, prior=c(75, 25)/100)
lda_model
# Projection of LD1 ------------------------------------------------------------
# 1. Get direction, where we have to project our data, to maximize
# variability between/variability within - ? as in FDA?
w <- lda_model$scaling[, 1] # solve(S) %*% (M1 - M0)
# 2. Проецируем все точки
lda_proj <- as.vector(as.matrix(data_all) %*% w)
# 3. Получаем проекции по группам
proj_atlantica <- lda_proj[Atalantica_index]
proj_iberica <- lda_proj[Iberica_index]
# 4. Оценим среднее и дисперсию на проекции
M_atlantica_proj <- mean(proj_atlantica)
M_iberica_proj <- mean(proj_iberica)
S_atlantica_proj <- cov(as.matrix(proj_atlantica))
S_iberica_proj <- cov(as.matrix(proj_iberica))
S_proj <- ((500-1) * S_atlantica_proj + (500-1) * S_iberica_proj) / (500 + 500 - 2)  # т.к. на проекции — одно измерение
# 5. Plot graphs
x <- seq(min(lda_proj), max(lda_proj), length.out = 500)
par(mfrow = c(2,1))
# Gaussian
plot(
x,
0.75 * dnorm(x, M_atlantica_proj, sqrt(S_proj)),
type = 'l',
col = 'blue',
ylab = expression(paste('estimated ', p[i] * f[i], '(x)')),
main = 'LDA (projection)'
)
lines(x, 0.25 * dnorm(x, M_iberica_proj, sqrt(S_proj)), col = 'red')
points(proj_atlantica, rep(0, length(proj_atlantica)), col = 'blue', pch = 16)
points(proj_iberica, rep(0, length(proj_iberica)), col = 'red', pch = 16)
legend("topright", legend=c("Atlantica", "Iberica"), col=c("blue", "red"), lty=1)
# posterior probability
posterior_atlantica <- 0.75 * dnorm(x, M_atlantica_proj, sqrt(S_proj)) / (
0.75 * dnorm(x, M_atlantica_proj, sqrt(S_proj)) + 0.25 * dnorm(x, M_iberica_proj, sqrt(S_proj))
)
posterior_iberica <- 1 - posterior_atlantica
par(mfrow = c(2,1))
# Gaussian
plot(
x,
0.75 * dnorm(x, M_atlantica_proj, sqrt(S_proj)),
type = 'l',
col = 'blue',
ylab = expression(paste('estimated ', p[i] * f[i], '(x)')),
main = 'LDA (projection)'
)
lines(x, 0.25 * dnorm(x, M_iberica_proj, sqrt(S_proj)), col = 'red')
points(proj_atlantica, rep(0, length(proj_atlantica)), col = 'blue', pch = 16)
points(proj_iberica, rep(0, length(proj_iberica)), col = 'red', pch = 16)
legend("topright", legend=c("Atlantica", "Iberica"), col=c("blue", "red"), lty=1)
# posterior probability
posterior_atlantica <- 0.75 * dnorm(x, M_atlantica_proj, sqrt(S_proj)) / (
0.75 * dnorm(x, M_atlantica_proj, sqrt(S_proj)) + 0.25 * dnorm(x, M_iberica_proj, sqrt(S_proj))
)
posterior_iberica <- 1 - posterior_atlantica
plot(x, posterior_atlantica, type = 'l', col = 'blue', ylab = 'estimated posterior')
lines(x, posterior_iberica, col = 'red')
legend("topright", legend=c("P(Class 0 | x)", "P(Class 1 | x)"), col=c("blue", "red"), lty=1)
par(mfrow = c(1,1))
# c)
predictions <- predict(lda_model, as.matrix(data_all))$class
predictions
# Confusion matrix components
TP_lda <- sum(predictions == "Atlantica" & labels_all == "Atlantica")
FP_lda <- sum(predictions == "Atlantica" & labels_all == "Iberica")
FN_lda <- sum(predictions == "Iberica" & labels_all == "Atlantica")
TN_lda <- sum(predictions == "Iberica" & labels_all == "Iberica")
AER <- 0.75 * FN_lda/500 + 0.25 * FP_lda/500
AER
# APER
Qda.m <- predict(qda.m)
true <- read.table('moneytrue.txt', header=TRUE)
false <- read.table('moneyfalse.txt', header=TRUE)
banknotes <- rbind(true,false)
vf <- factor(rep(c('true','false'),each=100), levels=c('true','false'))
plot(banknotes[,1:2], main='Banknotes', xlab='V1', ylab='V2', pch=20)
points(false, col='red', pch=20)
points(true, col='blue', pch=20)
legend('bottomleft', legend=levels(vf), fill=c('blue','red'), cex=.7)
# question a)
library(MVN)
mvn(true)$multivariateNormality
mvn(false)$multivariateNormality
# misclassification costs
c.tf <- 10
c.ft <- 0.05
#prior probabilities
pf <- 0.001
pt <- 1-0.001
prior = c(pt, pf)
prior
# Prior modified to account for the misclassification costs
prior.c <- c(pt*c.ft/(c.tf*pf+c.ft*pt), pf*c.tf/(c.tf*pf+c.ft*pt))
prior.c
# QDA
# Due to each group have their own covariance matrix, we can not project
# data on common vector and plot prob distribution
qda.m <- qda(banknotes, vf, prior=prior.c)
# R LDA function
library(MASS)
## Comparison with k-Nearest Neighbor (k-NN) classifier ----------------------------------------
library(class)
help(qda)
# QDA
# Due to each group have their own covariance matrix, we can not project
# data on common vector and plot prob distribution
qda.m <- qda(banknotes, vf, prior=prior.c)
qda.m
plot(banknotes[,1:2], main='Banknotes', xlab='V1', ylab='V2', pch=20)
points(false, col='red', pch=20)
points(true, col='blue', pch=20)
legend('bottomleft', legend=levels(vf), fill=c('blue','red'), cex=.7)
points(qda.m$means, pch=4,col=c('red','blue') , lwd=2, cex=1.5)
x  <- seq(min(banknotes[,1]), max(banknotes[,1]), length=200)
y  <- seq(min(banknotes[,2]), max(banknotes[,2]), length=200)
xy <- expand.grid(V1=x, V2=y)
z  <- predict(qda.m, xy)$post
z1 <- z[,1] - z[,2]
z2 <- z[,2] - z[,1]
contour(x, y, matrix(z1, 200), levels=0, drawlabels=F, add=T)
contour(x, y, matrix(z2, 200), levels=0, drawlabels=F, add=T)
m1 <- colMeans(true)
m2 <- colMeans(false)
S1 <- cov(true)
S2 <- cov(false)
open3d()
points3d(true[,1], true[,2], 0, col='blue', pch=15)
# APER
Qda.m <- predict(qda.m)
table(class.true=vf, class.assigned=Qda.m$class)
# APER
Qda.m <- predict(qda.m)
table(class.true=vf, class.assigned=Qda.m$class)
pt
pf
true <- read.table('moneytrue.txt', header=TRUE)
false <- read.table('moneyfalse.txt', header=TRUE)
true
length(true)
nrow(true)
nrow(false)
table(class.true=vf, class.assigned=Qda.m$class)
c.ft
